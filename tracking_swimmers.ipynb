{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ron-po/tracking-swimmers/blob/main/tracking_swimmers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z88Pe_LeTspA"
      },
      "source": [
        "Start here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EU3XQm8702Qe",
        "outputId": "d673bbcb-5d03-470a-d17d-dab464c480cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of video or cannot read frame.\n",
            "\n",
            "Done processing video. Saved as: red_lines_mask.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import DBSCAN\n",
        "from collections import Counter\n",
        "import imageio\n",
        "import os\n",
        "\n",
        "# Get Red Lines Mask\n",
        "\n",
        "def largest_connected_component(mask):\n",
        "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask, connectivity=8)\n",
        "    if num_labels <= 1:\n",
        "        return mask\n",
        "    largest_label = 1\n",
        "    largest_area = stats[1, cv2.CC_STAT_AREA]\n",
        "    for i in range(2, num_labels):\n",
        "        area = stats[i, cv2.CC_STAT_AREA]\n",
        "        if area > largest_area:\n",
        "            largest_area = area\n",
        "            largest_label = i\n",
        "    largest_mask = np.zeros_like(mask, dtype=np.uint8)\n",
        "    largest_mask[labels == largest_label] = 255\n",
        "    return largest_mask\n",
        "\n",
        "def detect_pool(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    lower_blue = np.array([40, 50, 50])\n",
        "    upper_blue = np.array([130, 240, 220])\n",
        "    pool_mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "    pool_mask = largest_connected_component(pool_mask)\n",
        "\n",
        "    # Find contours around the pool\n",
        "    contours, _ = cv2.findContours(pool_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if len(contours) == 0:\n",
        "        print(\"No pool found!\")\n",
        "        return None\n",
        "\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    # Draw the largest contour (assuming it's the pool)\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)  # Get the largest contour\n",
        "\n",
        "    # Create an empty mask\n",
        "    filled_mask = np.zeros_like(pool_mask)\n",
        "\n",
        "    # Fill in the detected pool area\n",
        "    cv2.drawContours(filled_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
        "\n",
        "    return filled_mask  # Return the filled mask instead of the contour\n",
        "\n",
        "def remove_blues_and_blacks(image):\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Define range for blue and black in HSV space\n",
        "    lower_blue = np.array([90, 50, 50])  # Lower bound for blue\n",
        "    upper_blue = np.array([150, 255, 255])  # Upper bound for blue\n",
        "\n",
        "    # Define range for black (low saturation and value) in HSV space\n",
        "    lower_black = np.array([0, 0, 0])\n",
        "    upper_black = np.array([180, 255, 50])  # Very dark colors\n",
        "\n",
        "    # Create masks for blue and black\n",
        "    blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "    black_mask = cv2.inRange(hsv, lower_black, upper_black)\n",
        "\n",
        "    # Combine the two masks (blue and black)\n",
        "    combined_mask = cv2.bitwise_or(blue_mask, black_mask)\n",
        "\n",
        "    # Invert the mask to keep everything except blue and black\n",
        "    inverted_mask = cv2.bitwise_not(combined_mask)\n",
        "\n",
        "    return inverted_mask\n",
        "\n",
        "def detect_lane_lines(image):\n",
        "    # Convert to grayscale (needed for edge detection)\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur to reduce noise and improve edge detection\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Use Canny edge detection to find edges\n",
        "    edges = cv2.Canny(blurred, 50, 150)\n",
        "\n",
        "    # Detect lines using Hough Line Transform\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=50, maxLineGap=50)\n",
        "\n",
        "    # Draw detected lines in red\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # red lines\n",
        "\n",
        "    return image, lines\n",
        "\n",
        "def theta_from_slope(slope):\n",
        "    return np.degrees(np.arctan(slope))\n",
        "\n",
        "def remove_outliers(merged_lines):\n",
        "    \"\"\"\n",
        "    Remove outliers from a list of nearly parallel lines based on their slopes.\n",
        "    Keep the set of slopes that is most common.\n",
        "    merged_lines: NumPy array of shape (n, 4), where each row represents a line (x1, y1, x2, y2)\n",
        "    \"\"\"\n",
        "    # Calculate angles for each line\n",
        "    lines = merged_lines[:, 0]\n",
        "    thetas = [theta_from_slope(line) for line in lines]\n",
        "\n",
        "    # Find the median angle\n",
        "    median_angle = np.median(thetas)\n",
        "\n",
        "    # Set a threshold for outlier removal (based on a small deviation from the most common angle)\n",
        "    threshold = 5  # Adjust threshold as needed\n",
        "\n",
        "    filtered_lines = []\n",
        "    for i, line in enumerate(merged_lines[:, 0]):\n",
        "        angle_deg = theta_from_slope(line)\n",
        "        if np.abs(angle_deg - median_angle) <= threshold:\n",
        "            filtered_lines.append(merged_lines[i])\n",
        "\n",
        "    return np.array(filtered_lines)\n",
        "\n",
        "def merge_lane_lines(lines, max_height=10000, slope_threshold=0.2, intercept_threshold=20):\n",
        "    if lines is None:\n",
        "        return []\n",
        "\n",
        "    merged_lines = []\n",
        "\n",
        "    # Group lines with similar slopes and intercepts\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "        if x2 - x1 != 0:  # Prevent division by zero\n",
        "            slope = (y2 - y1) / (x2 - x1)\n",
        "            intercept = y1 - slope * x1  # y = mx + b -> b = y - mx\n",
        "\n",
        "            if intercept < 0 or intercept > max_height:\n",
        "                continue\n",
        "\n",
        "            merged = False\n",
        "            for idx, (m, b) in enumerate(merged_lines):\n",
        "                if abs(slope - m) < slope_threshold and abs(intercept - b) < intercept_threshold:\n",
        "                    merged_lines[idx] = ((m + slope) / 2, (b + intercept) / 2)\n",
        "                    merged = True\n",
        "                    break\n",
        "\n",
        "            if not merged:\n",
        "                merged_lines.append((slope, intercept))\n",
        "\n",
        "    merged_lines = np.array(merged_lines)\n",
        "    merged_lines = remove_outliers(merged_lines)\n",
        "    merged_lines = merged_lines[merged_lines[:, 1].argsort()]\n",
        "\n",
        "    return merged_lines\n",
        "\n",
        "def draw_merged_lines(image, merged_lines):\n",
        "    # Draw merged lane lines in red\n",
        "    for slope, intercept in merged_lines:\n",
        "        x1 = 0\n",
        "        x2 = int(image.shape[1])\n",
        "        y1 = int(intercept)\n",
        "        y2 = int(slope * x2 + intercept)\n",
        "        cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # red line\n",
        "\n",
        "    return image\n",
        "\n",
        "def rotate_image(image, theta):\n",
        "    (height, width) = image.shape[:2]\n",
        "    center = (width // 2, height // 2)\n",
        "    rotation_matrix = cv2.getRotationMatrix2D(center, theta, 1.0)\n",
        "    rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height), flags=cv2.INTER_LINEAR)\n",
        "    return rotated_image\n",
        "\n",
        "# Modified crop_lane: cropping is removed so the full image is returned.\n",
        "def crop_lane(image, lane, merged_lines):\n",
        "    # Simply return the original image (no cropping performed)\n",
        "    return image, image\n",
        "\n",
        "rotation_angles = []\n",
        "\n",
        "def process(frame, lane, old_merged_lines):\n",
        "    pool_mask = detect_pool(frame)\n",
        "    pool = cv2.bitwise_and(frame, frame, mask=pool_mask)\n",
        "    blue_black_mask = remove_blues_and_blacks(pool)\n",
        "    pool_no_blue = cv2.bitwise_and(pool, pool, mask=blue_black_mask)\n",
        "    result_image, lines = detect_lane_lines(pool_no_blue)\n",
        "    new_merged_lines = merge_lane_lines(lines, frame.shape[0])\n",
        "    if len(new_merged_lines) >= lane:\n",
        "        old_merged_lines = new_merged_lines\n",
        "\n",
        "    # Create a black image\n",
        "    blacked_out_image = np.zeros_like(frame)\n",
        "\n",
        "    # Draw only the final kept red lines on the black background\n",
        "    for slope, intercept in old_merged_lines:\n",
        "        x1 = 0\n",
        "        x2 = int(frame.shape[1])\n",
        "        y1 = int(intercept)\n",
        "        y2 = int(slope * x2 + intercept)\n",
        "        cv2.line(blacked_out_image, (x1, y1), (x2, y2), (0, 0, 255), 4)  # Red lines on black background\n",
        "\n",
        "    avg_slope = (old_merged_lines[lane - 2, 0] + old_merged_lines[lane - 1, 0]) / 2\n",
        "    theta = theta_from_slope(avg_slope)\n",
        "\n",
        "    rotation_angles.append(theta)\n",
        "\n",
        "    # Rotate the blacked-out image with red lines\n",
        "    rotated_image = rotate_image(blacked_out_image, theta)\n",
        "\n",
        "    # Apply rotation to the final output by using the rotated image in the crop_lane function.\n",
        "    cropped_image, masked_lane = crop_lane(rotated_image, lane, old_merged_lines)\n",
        "\n",
        "    return old_merged_lines, cropped_image, masked_lane\n",
        "\n",
        "\n",
        "\n",
        "# Main execution to process a video and save the output\n",
        "video_path = \"200free.mp4\"  # Ensure the video is in the same folder\n",
        "lane = 3\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video '{video_path}'. Check if it's uploaded.\")\n",
        "else:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: No frames in the video.\")\n",
        "        cap.release()\n",
        "    else:\n",
        "        old_merged_lines = np.array([])\n",
        "        old_merged_lines, cropped_image, masked_image = process(frame, lane, old_merged_lines)\n",
        "\n",
        "        height, width = masked_image.shape[:2]\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        output_path = \"red_lines_mask.mp4\"\n",
        "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "        out.write(masked_image)\n",
        "\n",
        "        frame_num = 1\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                print(\"End of video or cannot read frame.\")\n",
        "                break\n",
        "            old_merged_lines, cropped_image, masked_image = process(frame, lane, old_merged_lines)\n",
        "            out.write(masked_image)\n",
        "\n",
        "\n",
        "            frame_num += 1\n",
        "\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(\"\\nDone processing video. Saved as:\", output_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJMzBp9kkIFS",
        "outputId": "4a8bee89-c0f9-4d55-c10f-749d9f290c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete.\n",
            " - Full color video with green overlay saved as: tracked_swimmers.mp4\n",
            " - Black-and-white difference video saved as: non_water_mask.mp4\n"
          ]
        }
      ],
      "source": [
        "# Get only swimmers and lanes - while matching dimensions to red_lines_mask\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Video Paths\n",
        "video_path = \"200free.mp4\"\n",
        "output_path = \"tracked_swimmers.mp4\"  # Color video with non-water overlay\n",
        "difference_output_path = \"non_water_mask.mp4\"  # Black-and-white difference video\n",
        "\n",
        "# Open the video and get properties\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video {video_path}.\")\n",
        "    exit()\n",
        "\n",
        "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "# Define HSV thresholds for detecting pool water (blue color)\n",
        "lower_blue = np.array([40, 50, 50])\n",
        "upper_blue = np.array([130, 255, 255])\n",
        "\n",
        "# Initialize video writers (keeping original resolution)\n",
        "out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "out_diff = cv2.VideoWriter(difference_output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# ========================\n",
        "# Process Each Frame\n",
        "# ========================\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # End of video\n",
        "\n",
        "    # Convert frame to HSV\n",
        "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "    pool_mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
        "\n",
        "    # Find contours in the pool mask and select the largest (assumed to be the pool area)\n",
        "    contours, _ = cv2.findContours(pool_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if contours:\n",
        "        largest_contour = max(contours, key=cv2.contourArea)\n",
        "        connected_mask = np.zeros_like(pool_mask)\n",
        "        cv2.drawContours(connected_mask, [largest_contour], -1, 255, thickness=-1)\n",
        "\n",
        "        # Compute non-water regions: subtract pool mask from connected mask\n",
        "        non_water_mask = cv2.subtract(connected_mask, pool_mask)\n",
        "    else:\n",
        "        # If no pool detected, assume entire frame is non-water\n",
        "        non_water_mask = np.zeros_like(pool_mask)\n",
        "\n",
        "    # ===========================\n",
        "    # Generate Overlay Output\n",
        "    # ===========================\n",
        "    water_region = cv2.bitwise_and(frame, frame, mask=pool_mask)\n",
        "    final_frame = water_region.copy()\n",
        "    final_frame[non_water_mask == 255] = (0, 255, 0)  # Highlight non-water in green\n",
        "\n",
        "    # Write full-resolution frame with green overlay\n",
        "    out.write(final_frame)\n",
        "\n",
        "    # ===========================\n",
        "    # Generate Black-and-White Mask Output\n",
        "    # ===========================\n",
        "    diff_image = np.zeros_like(frame)  # Black background\n",
        "    diff_image[non_water_mask == 255] = (255, 255, 255)  # White for non-water regions\n",
        "\n",
        "    # Write full-resolution difference mask\n",
        "    out_diff.write(diff_image)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "out_diff.release()\n",
        "\n",
        "print(f\"Processing complete.\\n\"\n",
        "      f\" - Full color video with green overlay saved as: {output_path}\\n\"\n",
        "      f\" - Black-and-white difference video saved as: {difference_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRFjNSdObFqU",
        "outputId": "bf9fde6e-41a3-4e72-8c4f-de120d7a39c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of non_water_mask video or cannot read frame.\n",
            "Rotated non_water_mask video saved as non_water_mask_rotated.mp4\n"
          ]
        }
      ],
      "source": [
        "# Rotate non_water_mask to align with red_lines_mask\n",
        "\n",
        "\n",
        "# rotation angles obtained from previous script\n",
        "rotation_angles\n",
        "\n",
        "# Open non_water_mask video\n",
        "non_water_video_path = \"non_water_mask.mp4\"\n",
        "cap_non_water = cv2.VideoCapture(non_water_video_path)\n",
        "\n",
        "if not cap_non_water.isOpened():\n",
        "    print(f\"Error: Could not open video '{non_water_video_path}'.\")\n",
        "else:\n",
        "    # Get video properties\n",
        "    fps = int(cap_non_water.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap_non_water.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap_non_water.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    output_path = \"non_water_mask_rotated.mp4\"\n",
        "    out_non_water = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_index = 0\n",
        "    while True:\n",
        "        ret, frame = cap_non_water.read()\n",
        "        if not ret:\n",
        "            print(\"End of non_water_mask video or cannot read frame.\")\n",
        "            break\n",
        "\n",
        "        if frame_index < len(rotation_angles):\n",
        "            theta = rotation_angles[frame_index]  # Correct index usage\n",
        "        else:\n",
        "            print(f\"Warning: Missing rotation angle for frame {frame_index}. Using last available angle.\")\n",
        "            theta = rotation_angles[-1]\n",
        "\n",
        "        # Rotate the frame by the corresponding angle\n",
        "        (h, w) = frame.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(center, theta, 1.0)\n",
        "        rotated_frame = cv2.warpAffine(frame, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
        "\n",
        "        out_non_water.write(rotated_frame)\n",
        "        frame_index += 1\n",
        "\n",
        "    # Release everything\n",
        "    cap_non_water.release()\n",
        "    out_non_water.release()\n",
        "\n",
        "    print(f\"Rotated non_water_mask video saved as {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rotate non_water_mask to align with red_lines_mask\n",
        "\n",
        "\n",
        "# rotation angles obtained from previous script\n",
        "rotation_angles\n",
        "\n",
        "# Open non_water_mask video\n",
        "non_water_video_path = \"200free.mp4\"\n",
        "cap_non_water = cv2.VideoCapture(non_water_video_path)\n",
        "\n",
        "if not cap_non_water.isOpened():\n",
        "    print(f\"Error: Could not open video '{non_water_video_path}'.\")\n",
        "else:\n",
        "    # Get video properties\n",
        "    fps = int(cap_non_water.get(cv2.CAP_PROP_FPS))\n",
        "    width = int(cap_non_water.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap_non_water.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    output_path = \"200free_rotated.mp4\"\n",
        "    out_non_water = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_index = 0\n",
        "    while True:\n",
        "        ret, frame = cap_non_water.read()\n",
        "        if not ret:\n",
        "            print(\"End of non_water_mask video or cannot read frame.\")\n",
        "            break\n",
        "\n",
        "        if frame_index < len(rotation_angles):\n",
        "            theta = rotation_angles[frame_index]  # Correct index usage\n",
        "        else:\n",
        "            print(f\"Warning: Missing rotation angle for frame {frame_index}. Using last available angle.\")\n",
        "            theta = rotation_angles[-1]\n",
        "\n",
        "        # Rotate the frame by the corresponding angle\n",
        "        (h, w) = frame.shape[:2]\n",
        "        center = (w // 2, h // 2)\n",
        "        rotation_matrix = cv2.getRotationMatrix2D(center, theta, 1.0)\n",
        "        rotated_frame = cv2.warpAffine(frame, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
        "\n",
        "        out_non_water.write(rotated_frame)\n",
        "        frame_index += 1\n",
        "\n",
        "    # Release everything\n",
        "    cap_non_water.release()\n",
        "    out_non_water.release()\n",
        "\n",
        "    print(f\"Rotated non_water_mask video saved as {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRqA5nbdAWLT",
        "outputId": "56b69a40-dd25-4105-ba36-b577bd593bd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of non_water_mask video or cannot read frame.\n",
            "Rotated non_water_mask video saved as 200free_rotated.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoEzBkMRniA2",
        "outputId": "7bca232c-4bb3-4251-ce99-9213bdcdac6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected lane boundaries (y_top, y_bottom): [(377, 426), (426, 482), (482, 551), (551, 619), (619, 706)]\n",
            "Processing complete. Videos saved as:\n",
            " - Blacked-out version: final_overlay_black.mp4\n",
            " - Red overlay version: final_overlay_red.mp4\n"
          ]
        }
      ],
      "source": [
        "# Track swimmers\n",
        "\n",
        "red_lines_video = \"red_lines_mask.mp4\"\n",
        "non_water_video = \"non_water_mask_rotated.mp4\"\n",
        "output_black = \"final_overlay_black.mp4\"\n",
        "output_red = \"final_overlay_red.mp4\"\n",
        "\n",
        "# Open both videos\n",
        "cap_red = cv2.VideoCapture(red_lines_video)\n",
        "cap_non_water = cv2.VideoCapture(non_water_video)\n",
        "\n",
        "# Check if videos opened successfully\n",
        "if not cap_red.isOpened() or not cap_non_water.isOpened():\n",
        "    print(\"Error: Could not open one or both videos.\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties (assuming both have the same properties)\n",
        "fps = int(cap_red.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap_red.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap_red.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "# Initialize video writers\n",
        "out_black = cv2.VideoWriter(output_black, fourcc, fps, (frame_width, frame_height))\n",
        "out_red = cv2.VideoWriter(output_red, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# Define red color range in HSV (for better detection)\n",
        "lower_hsv_red = np.array([0, 120, 100])   # Lower bound for red\n",
        "upper_hsv_red = np.array([10, 255, 255])    # Upper bound for red\n",
        "\n",
        "# ------------------------------------------------------------------\n",
        "# AUTOMATIC RED LANE DETECTION & STORAGE (using the first frame)\n",
        "# ------------------------------------------------------------------\n",
        "# Read the first frame from the red-lines video\n",
        "ret_first, first_frame_red = cap_red.read()\n",
        "if not ret_first:\n",
        "    print(\"Error: Could not read first frame from red_lines_mask.mp4\")\n",
        "    exit()\n",
        "\n",
        "# Convert to HSV and create a red mask\n",
        "hsv_first = cv2.cvtColor(first_frame_red, cv2.COLOR_BGR2HSV)\n",
        "red_mask_first = cv2.inRange(hsv_first, lower_hsv_red, upper_hsv_red)\n",
        "\n",
        "# Thicken the red lines (same as below)\n",
        "kernel = np.ones((5, 5), np.uint8)\n",
        "thickened_mask_first = cv2.dilate(red_mask_first, kernel, iterations=2)\n",
        "# Further thicken the bottom half of the frame\n",
        "bottom_part_first = thickened_mask_first[frame_height // 2:]\n",
        "extra_thick_kernel = np.ones((7, 7), np.uint8)\n",
        "bottom_part_thicker_first = cv2.dilate(bottom_part_first, extra_thick_kernel, iterations=4)\n",
        "thickened_mask_first[frame_height // 2:] = bottom_part_thicker_first\n",
        "\n",
        "# Automatically detect red lines by scanning rows\n",
        "min_line_pixel_count = 50  # Adjust threshold as needed\n",
        "line_rows = []\n",
        "for row in range(frame_height):\n",
        "    if np.sum(thickened_mask_first[row, :] == 255) > min_line_pixel_count:\n",
        "        line_rows.append(row)\n",
        "\n",
        "# Group consecutive rows into single lines\n",
        "line_groups = []\n",
        "if line_rows:\n",
        "    current_group = [line_rows[0]]\n",
        "    for i in range(1, len(line_rows)):\n",
        "        if line_rows[i] == line_rows[i-1] + 1:\n",
        "            current_group.append(line_rows[i])\n",
        "        else:\n",
        "            line_groups.append(current_group)\n",
        "            current_group = [line_rows[i]]\n",
        "    if current_group:\n",
        "        line_groups.append(current_group)\n",
        "else:\n",
        "    print(\"Warning: No red lines detected.\")\n",
        "\n",
        "# Compute average row for each detected red line\n",
        "red_line_positions = [int(sum(group)/len(group)) for group in line_groups]\n",
        "red_line_positions.sort()\n",
        "\n",
        "# Only consider the topmost 6 red lines (from top of image to bottom)\n",
        "if len(red_line_positions) >= 6:\n",
        "    lane_line_positions = red_line_positions[:6]\n",
        "else:\n",
        "    lane_line_positions = red_line_positions\n",
        "\n",
        "# Compute lane boundaries (5 lanes between 6 lines)\n",
        "lane_bounds = []\n",
        "for i in range(len(lane_line_positions) - 1):\n",
        "    lane_bounds.append((lane_line_positions[i], lane_line_positions[i+1]))\n",
        "print(\"Detected lane boundaries (y_top, y_bottom):\", lane_bounds)\n",
        "\n",
        "# Reset red-lines video to beginning (if needed)\n",
        "cap_red.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "\n",
        "# ========================\n",
        "# Process Each Frame for Final Overlays\n",
        "# ========================\n",
        "while True:\n",
        "    ret_red, frame_red = cap_red.read()\n",
        "    ret_non_water, frame_non_water = cap_non_water.read()\n",
        "\n",
        "    if not ret_red or not ret_non_water:\n",
        "        break  # Stop if either video ends\n",
        "\n",
        "    # Convert red_lines_mask frame to HSV for better red detection\n",
        "    hsv_red = cv2.cvtColor(frame_red, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    # Create mask for red pixels\n",
        "    red_mask = cv2.inRange(hsv_red, lower_hsv_red, upper_hsv_red)\n",
        "\n",
        "    # **Thicken all lane lines slightly**\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    thickened_mask = cv2.dilate(red_mask, kernel, iterations=2)\n",
        "\n",
        "    # **Identify Bottom 3 Lane Lines & Thicken Them More**\n",
        "    bottom_part = thickened_mask[frame_height // 2:]\n",
        "    extra_thick_kernel = np.ones((7, 7), np.uint8)\n",
        "    bottom_part_thicker = cv2.dilate(bottom_part, extra_thick_kernel, iterations=4)\n",
        "\n",
        "    # **Merge top and thickened bottom**\n",
        "    thickened_mask[frame_height // 2:] = bottom_part_thicker\n",
        "\n",
        "    # Overwrite pixels: create final_frame_black by drawing black over detected red regions.\n",
        "    final_frame_black = frame_non_water.copy()\n",
        "    contours, _ = cv2.findContours(thickened_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    cv2.drawContours(final_frame_black, contours, -1, (0, 0, 0), thickness=cv2.FILLED)\n",
        "\n",
        "    # Similarly, create final_frame_red by drawing red over detected regions.\n",
        "    final_frame_red = frame_non_water.copy()\n",
        "    cv2.drawContours(final_frame_red, contours, -1, (0, 0, 255), thickness=cv2.FILLED)\n",
        "\n",
        "    # Write frames to both output videos\n",
        "    out_black.write(final_frame_black)\n",
        "    out_red.write(final_frame_red)\n",
        "\n",
        "# Release everything\n",
        "cap_red.release()\n",
        "cap_non_water.release()\n",
        "out_black.release()\n",
        "out_red.release()\n",
        "\n",
        "print(f\"Processing complete. Videos saved as:\\n\"\n",
        "      f\" - Blacked-out version: {output_black}\\n\"\n",
        "      f\" - Red overlay version: {output_red}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ3sN9zlV0hg",
        "outputId": "c7749c10-ad20-434b-da75-f12f2e48ac6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video relevant_vid.mp4.\n",
            "Moviepy - Writing video relevant_vid.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready relevant_vid.mp4\n"
          ]
        }
      ],
      "source": [
        "#Black out irrelevant regions\n",
        "\n",
        "from moviepy.editor import VideoFileClip, VideoClip, CompositeVideoClip\n",
        "import numpy as np\n",
        "\n",
        "# Load the original video\n",
        "clip = VideoFileClip(\"final_overlay_red.mp4\")\n",
        "w, h = clip.size\n",
        "fps = clip.fps\n",
        "\n",
        "# Define the time (in seconds) at which to start expanding the blackout region.\n",
        "T0 = 380 / fps  # frame 350\n",
        "\n",
        "# Define the initial and final blackout heights.\n",
        "initial_height = int(0.35 * h)   # initial height to black out (from bottom)\n",
        "final_height = int(0.45 * h)            # final blackout height after transition\n",
        "\n",
        "# Define the duration over which the transition will occur (in seconds)\n",
        "T_transition = 2.0  # adjust as needed for a smoother transition\n",
        "\n",
        "# Function to generate the black rectangle frame dynamically.\n",
        "def black_rect_frame(t):\n",
        "    if t < T0:\n",
        "        current_height = initial_height\n",
        "    elif t < T0 + T_transition:\n",
        "        progress = (t - T0) / T_transition\n",
        "        current_height = int((1 - progress) * initial_height + progress * final_height)\n",
        "    else:\n",
        "        current_height = final_height\n",
        "    # Create a black image with the computed height.\n",
        "    return np.zeros((current_height, w, 3), dtype=np.uint8)\n",
        "\n",
        "# Function to position the black rectangle so that its bottom aligns with the video bottom.\n",
        "def black_pos(t):\n",
        "    if t < T0:\n",
        "        current_height = initial_height\n",
        "    elif t < T0 + T_transition:\n",
        "        progress = (t - T0) / T_transition\n",
        "        current_height = int((1 - progress) * initial_height + progress * final_height)\n",
        "    else:\n",
        "        current_height = final_height\n",
        "    # Position it at the bottom: x=0, y = video height - current_height.\n",
        "    return (0, h - current_height)\n",
        "\n",
        "# Create a dynamic black clip that lasts the duration of the original clip.\n",
        "black_clip = VideoClip(black_rect_frame, duration=clip.duration)\n",
        "black_clip = black_clip.set_pos(black_pos)\n",
        "\n",
        "# Overlay the dynamic black clip on top of the original clip.\n",
        "final_clip = CompositeVideoClip([clip, black_clip])\n",
        "\n",
        "# Write the result to a new video file.\n",
        "final_clip.write_videofile(\"relevant_vid.mp4\", codec=\"libx264\", audio_codec=\"aac\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "\n",
        "# # Ensure that lane_bounds (a list of 5 tuples) is available from Cell 1.\n",
        "# print(\"Using lane bounds:\", lane_bounds)\n",
        "\n",
        "# # Input video path for final overlay red video\n",
        "# overlay_red_video = \"relevant_vid.mp4\"\n",
        "# cap_swimmers = cv2.VideoCapture(overlay_red_video)\n",
        "# if not cap_swimmers.isOpened():\n",
        "#     print(\"Error: Could not open\", overlay_red_video)\n",
        "#     exit()\n",
        "\n",
        "# fps = int(cap_swimmers.get(cv2.CAP_PROP_FPS))\n",
        "# frame_width = int(cap_swimmers.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# frame_height = int(cap_swimmers.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "# out_swimmers = cv2.VideoWriter(\"tracked_swimmers.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# frame_index = 0\n",
        "# # Dictionary to store current centroid for each lane (keys: 0 to 4)\n",
        "# centroids = {}\n",
        "# # Dictionary to store previous centroids (for speed computation)\n",
        "# prev_centroids = {}\n",
        "\n",
        "# # Conversion factor: 61.8 pixels per yard\n",
        "# pixels_per_yard = 61.8\n",
        "\n",
        "# while True:\n",
        "#     ret, frame = cap_swimmers.read()\n",
        "#     if not ret:\n",
        "#         break\n",
        "\n",
        "#     # Start tracking only after frame 100; before that, write unmodified frame.\n",
        "#     if frame_index < 100:\n",
        "#         out_swimmers.write(frame)\n",
        "#         frame_index += 1\n",
        "#         continue\n",
        "\n",
        "#     # Convert frame to grayscale and threshold to isolate white blobs (swimmers)\n",
        "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "#     # Adjust threshold if needed so that swimmers (white) remain bright.\n",
        "#     _, swimmer_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "#     # Process each of the 5 lanes (from lane_bounds)\n",
        "#     for lane_idx, (y_top, y_bottom) in enumerate(lane_bounds):\n",
        "#         if lane_idx >= 5:\n",
        "#             break  # only process 5 lanes\n",
        "\n",
        "#         # Extract the ROI corresponding to the lane (between the two red lines)\n",
        "#         lane_roi = swimmer_mask[y_top:y_bottom, :]\n",
        "#         contours, _ = cv2.findContours(lane_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "#         if contours:\n",
        "#             # Select the largest contour (assumed to be the swimmer)\n",
        "#             largest_contour = max(contours, key=cv2.contourArea)\n",
        "#             if cv2.contourArea(largest_contour) > 30:  # Filter out noise\n",
        "#                 M = cv2.moments(largest_contour)\n",
        "#                 if M[\"m00\"] != 0:\n",
        "#                     cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "#                     cy = int(M[\"m01\"] / M[\"m00\"]) + y_top  # adjust y-coordinate to full-frame\n",
        "#                     centroids[lane_idx] = (cx, cy)\n",
        "#         # If no blob is detected and it's the first tracking frame, initialize centroid on the left.\n",
        "#         if lane_idx not in centroids and frame_index == 100:\n",
        "#             init_x = int(0.1 * frame_width)  # initialize on the left (10% of frame width)\n",
        "#             init_y = int((y_top + y_bottom) / 2)\n",
        "#             centroids[lane_idx] = (init_x, init_y)\n",
        "\n",
        "#     # Compute speed for each lane (in yards per second) if previous centroid is available\n",
        "#     speeds = {}  # speed per lane in yd/s\n",
        "#     for lane_idx in range(5):\n",
        "#         if lane_idx in centroids and lane_idx in prev_centroids:\n",
        "#             (prev_x, prev_y) = prev_centroids[lane_idx]\n",
        "#             (curr_x, curr_y) = centroids[lane_idx]\n",
        "#             distance = np.sqrt((curr_x - prev_x) ** 2 + (curr_y - prev_y) ** 2)\n",
        "#             # Convert pixels per second to yards per second\n",
        "#             speeds[lane_idx] = (distance * fps) / pixels_per_yard\n",
        "#         else:\n",
        "#             speeds[lane_idx] = 0.0\n",
        "\n",
        "#     # Draw centroids, swimmer labels, and speed on the frame\n",
        "#     for lane_idx in range(5):\n",
        "#         if lane_idx in centroids:\n",
        "#             cx, cy = centroids[lane_idx]\n",
        "#             cv2.circle(frame, (cx, cy), 5, (0, 255, 0), -1)\n",
        "#             # Display swimmer label\n",
        "#             cv2.putText(frame, f\"Swimmer {lane_idx+1}\", (cx + 10, cy),\n",
        "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "#             # Display speed above the swimmer (20 pixels above the centroid)\n",
        "#             speed_text = f\"{speeds[lane_idx]:.1f} yd/s\"\n",
        "#             cv2.putText(frame, speed_text, (cx + 10, cy - 20),\n",
        "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "#     # Update previous centroids for next frame\n",
        "#     prev_centroids = centroids.copy()\n",
        "\n",
        "#     out_swimmers.write(frame)\n",
        "#     frame_index += 1\n",
        "\n",
        "# cap_swimmers.release()\n",
        "# out_swimmers.release()\n",
        "# print(\"Swimmer tracking complete. Output saved as 'tracked_swimmers.mp4'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfJQRTJyi16q",
        "outputId": "02d34a04-e568-4791-a6df-12ff03f46098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using lane bounds: [(377, 426), (426, 482), (482, 551), (551, 619), (619, 706)]\n",
            "Swimmer tracking complete. Output saved as 'tracked_swimmers.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Only centroids, no speeds\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(\"Using lane bounds:\", lane_bounds)\n",
        "\n",
        "overlay_red_video = \"relevant_vid.mp4\"\n",
        "cap_swimmers = cv2.VideoCapture(overlay_red_video)\n",
        "if not cap_swimmers.isOpened():\n",
        "    print(\"Error: Could not open\", overlay_red_video)\n",
        "    exit()\n",
        "\n",
        "fps = int(cap_swimmers.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap_swimmers.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap_swimmers.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out_swimmers = cv2.VideoWriter(\"only_centroids.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "frame_index = 0\n",
        "# Threshold frame: after 7 seconds, stop updating lane 5 (index 4) and shift labels.\n",
        "threshold_frame = int(7 * fps)\n",
        "\n",
        "# Dictionary to store current centroids (lane_idx -> (cx, cy))\n",
        "centroids = {}\n",
        "prev_centroids = {}\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap_swimmers.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # For the first 100 frames, write unmodified frame.\n",
        "    if frame_index < 100:\n",
        "        out_swimmers.write(frame)\n",
        "        frame_index += 1\n",
        "        continue\n",
        "\n",
        "    # Convert frame to grayscale and threshold to isolate white blobs (swimmers)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    _, swimmer_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Process each lane (using lane_bounds)\n",
        "    for lane_idx, (y_top, y_bottom) in enumerate(lane_bounds):\n",
        "        if lane_idx >= 5:\n",
        "            break  # only process 5 lanes\n",
        "\n",
        "        # After 7 seconds, do not update lane 5 (index 4)\n",
        "        if frame_index >= threshold_frame and lane_idx == 4:\n",
        "            continue\n",
        "\n",
        "        # Extract the ROI corresponding to the lane (between the two red lines)\n",
        "        lane_roi = swimmer_mask[y_top:y_bottom, :]\n",
        "        contours, _ = cv2.findContours(lane_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        new_centroid = None\n",
        "\n",
        "        if contours:\n",
        "            # Select the largest contour (assumed to be the swimmer)\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "            if cv2.contourArea(largest_contour) > 30:  # Filter out noise\n",
        "                M = cv2.moments(largest_contour)\n",
        "                if M[\"m00\"] != 0:\n",
        "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                    cy = int(M[\"m01\"] / M[\"m00\"]) + y_top  # adjust y-coordinate to full-frame\n",
        "                    new_centroid = (cx, cy)\n",
        "\n",
        "        # If no detection and it's the first tracking frame, initialize on the left.\n",
        "        if new_centroid is None and lane_idx not in centroids and frame_index == 100:\n",
        "            init_x = int(0.1 * frame_width)\n",
        "            init_y = int((y_top + y_bottom) / 2)\n",
        "            centroids[lane_idx] = (init_x, init_y)\n",
        "        elif new_centroid is not None:\n",
        "            centroids[lane_idx] = new_centroid\n",
        "\n",
        "    # Draw centroids and labels on the frame.\n",
        "    # For frames after 7 seconds, shift the labels by +1 and do not display lane 5.\n",
        "    for lane_idx in range(5):\n",
        "        if frame_index >= threshold_frame and lane_idx == 4:\n",
        "            continue\n",
        "        if lane_idx in centroids:\n",
        "            cx, cy = centroids[lane_idx]\n",
        "            cv2.circle(frame, (cx, cy), 5, (0, 255, 0), -1)\n",
        "            if frame_index >= threshold_frame:\n",
        "                label = f\"Swimmer {lane_idx+1+1}\"  # shift label by +1\n",
        "            else:\n",
        "                label = f\"Swimmer {lane_idx+1}\"\n",
        "            cv2.putText(frame, label, (cx + 10, cy),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    prev_centroids = centroids.copy()\n",
        "    out_swimmers.write(frame)\n",
        "    frame_index += 1\n",
        "\n",
        "cap_swimmers.release()\n",
        "out_swimmers.release()\n",
        "print(\"Swimmer tracking complete. Output saved as 'only_centroids.mp4'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFeTZTIjo0CH",
        "outputId": "7961d0fe-c8f9-4089-8b68-e8bf9a0403c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using lane bounds: [(377, 426), (426, 482), (482, 551), (551, 619), (619, 706)]\n",
            "Swimmer tracking complete. Output saved as 'only_centroids.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Remove bad labeling\n",
        "\n",
        "print(\"Using lane bounds:\", lane_bounds)\n",
        "\n",
        "overlay_red_video = \"relevant_vid.mp4\"\n",
        "cap_swimmers = cv2.VideoCapture(overlay_red_video)\n",
        "if not cap_swimmers.isOpened():\n",
        "    print(\"Error: Could not open\", overlay_red_video)\n",
        "    exit()\n",
        "\n",
        "fps = int(cap_swimmers.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap_swimmers.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap_swimmers.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out_swimmers = cv2.VideoWriter(\"tracked_swimmers.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "frame_index = 0\n",
        "# Threshold frame: after 7 seconds, stop updating lane index 4\n",
        "threshold_frame = int(7 * fps)\n",
        "\n",
        "# Dictionaries to store current centroids (lane_idx -> (cx, cy))\n",
        "# and previous centroids (for speed computation)\n",
        "centroids = {}\n",
        "prev_centroids = {}\n",
        "\n",
        "# Conversion factor: 61.8 pixels per yard\n",
        "pixels_per_yard = 61.8\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap_swimmers.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # For the first 100 frames, write unmodified frame.\n",
        "    if frame_index < 100:\n",
        "        out_swimmers.write(frame)\n",
        "        frame_index += 1\n",
        "        continue\n",
        "\n",
        "    # Convert frame to grayscale and threshold to isolate white blobs (swimmers)\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    _, swimmer_mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Process each lane (from lane_bounds)\n",
        "    for lane_idx, (y_top, y_bottom) in enumerate(lane_bounds):\n",
        "        if lane_idx >= 5:\n",
        "            break  # only process 5 lanes\n",
        "\n",
        "        # After 7 seconds, do not update lane 5 (index 4)\n",
        "        if frame_index >= threshold_frame and lane_idx == 4:\n",
        "            continue\n",
        "\n",
        "        # Extract the ROI corresponding to the lane (between the two red lines)\n",
        "        lane_roi = swimmer_mask[y_top:y_bottom, :]\n",
        "        contours, _ = cv2.findContours(lane_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        new_centroid = None\n",
        "\n",
        "        if contours:\n",
        "            # Select the largest contour (assumed to be the swimmer)\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "            if cv2.contourArea(largest_contour) > 30:  # Filter out noise\n",
        "                M = cv2.moments(largest_contour)\n",
        "                if M[\"m00\"] != 0:\n",
        "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                    cy = int(M[\"m01\"] / M[\"m00\"]) + y_top  # adjust y-coordinate to full-frame\n",
        "                    new_centroid = (cx, cy)\n",
        "\n",
        "        # If no detection and it's the first tracking frame, initialize on the left.\n",
        "        if new_centroid is None and lane_idx not in centroids and frame_index == 100:\n",
        "            init_x = int(0.1 * frame_width)\n",
        "            init_y = int((y_top + y_bottom) / 2)\n",
        "            centroids[lane_idx] = (init_x, init_y)\n",
        "        elif new_centroid is not None:\n",
        "            centroids[lane_idx] = new_centroid\n",
        "\n",
        "    # Compute speeds (in yards per second) for each lane (if previous centroid available)\n",
        "    speeds = {}\n",
        "    for lane_idx in range(5):\n",
        "        # For lane 5 (index 4) after 7 seconds, set speed to 0.\n",
        "        if frame_index >= threshold_frame and lane_idx == 4:\n",
        "            speeds[lane_idx] = 0.0\n",
        "            continue\n",
        "        if lane_idx in centroids and lane_idx in prev_centroids:\n",
        "            (prev_x, prev_y) = prev_centroids[lane_idx]\n",
        "            (curr_x, curr_y) = centroids[lane_idx]\n",
        "            distance = np.sqrt((curr_x - prev_x) ** 2 + (curr_y - prev_y) ** 2)\n",
        "            speeds[lane_idx] = (distance * fps) / pixels_per_yard\n",
        "        else:\n",
        "            speeds[lane_idx] = 0.0\n",
        "\n",
        "    # Draw centroids, labels, and speeds on the frame.\n",
        "    # For frames after 7 seconds, shift the labels by +1.\n",
        "    for lane_idx in range(5):\n",
        "        # Skip drawing lane 5 (swimmer 5) after 7 seconds.\n",
        "        if frame_index >= threshold_frame and lane_idx == 4:\n",
        "            continue\n",
        "        if lane_idx in centroids:\n",
        "            cx, cy = centroids[lane_idx]\n",
        "            cv2.circle(frame, (cx, cy), 5, (0, 255, 0), -1)\n",
        "            # If after 7 seconds, add 1 to the label.\n",
        "            if frame_index >= threshold_frame:\n",
        "                label = f\"Swimmer {lane_idx+1+1}\"  # shift label by +1\n",
        "            else:\n",
        "                label = f\"Swimmer {lane_idx+1}\"\n",
        "            cv2.putText(frame, label, (cx + 10, cy),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "            speed_text = f\"{speeds[lane_idx]:.1f} yd/s\"\n",
        "            cv2.putText(frame, speed_text, (cx + 10, cy - 20),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1, cv2.LINE_AA)\n",
        "\n",
        "    prev_centroids = centroids.copy()\n",
        "    out_swimmers.write(frame)\n",
        "    frame_index += 1\n",
        "\n",
        "cap_swimmers.release()\n",
        "out_swimmers.release()\n",
        "print(\"Swimmer tracking complete. Output saved as 'tracked_swimmers.mp4'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6GKsAl9g37K",
        "outputId": "73e0d46f-151b-4616-b756-27ec7a1c2fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using lane bounds: [(377, 426), (426, 482), (482, 551), (551, 619), (619, 706)]\n",
            "Swimmer tracking complete. Output saved as 'tracked_swimmers.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(\"Using lane bounds:\", lane_bounds)\n",
        "\n",
        "# Open the tracked swimmers video (which contains the tracking data) and the original video\n",
        "cap_tracked = cv2.VideoCapture(\"tracked_swimmers.mp4\")\n",
        "cap_original = cv2.VideoCapture(\"200free_rotated.mp4\")\n",
        "\n",
        "if not cap_tracked.isOpened() or not cap_original.isOpened():\n",
        "    print(\"Error: Could not open one or both videos.\")\n",
        "    exit()\n",
        "\n",
        "fps = int(cap_original.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap_original.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap_original.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out_final = cv2.VideoWriter(\"final_tracked_200free.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "frame_index = 0\n",
        "# Dictionaries to store centroids for each lane (keys: 0 to 4)\n",
        "centroids = {}\n",
        "prev_centroids = {}\n",
        "\n",
        "# Conversion factor: 61.8 pixels per yard\n",
        "pixels_per_yard = 61.8\n",
        "\n",
        "# Dim factor (to make the video a bit darker for overlay clarity)\n",
        "dim_factor = 0.7\n",
        "\n",
        "while True:\n",
        "    ret_tracked, frame_tracked = cap_tracked.read()\n",
        "    ret_original, frame_original = cap_original.read()\n",
        "\n",
        "    if not ret_tracked or not ret_original:\n",
        "        break\n",
        "\n",
        "    # For the first 100 frames, output the dimmed original frame unmodified.\n",
        "    if frame_index < 100:\n",
        "        frame_dimmed = cv2.convertScaleAbs(frame_original, alpha=dim_factor, beta=0)\n",
        "        out_final.write(frame_dimmed)\n",
        "        frame_index += 1\n",
        "        continue\n",
        "\n",
        "    # Process the tracked video frame to re-extract swimmer centroids.\n",
        "    gray_tracked = cv2.cvtColor(frame_tracked, cv2.COLOR_BGR2GRAY)\n",
        "    _, swimmer_mask = cv2.threshold(gray_tracked, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Process each of the 5 lanes (using lane_bounds)\n",
        "    for lane_idx, (y_top, y_bottom) in enumerate(lane_bounds):\n",
        "        if lane_idx >= 5:\n",
        "            break  # only process 5 lanes\n",
        "\n",
        "        # Extract ROI corresponding to the lane (between the two red lines)\n",
        "        lane_roi = swimmer_mask[y_top:y_bottom, :]\n",
        "        contours, _ = cv2.findContours(lane_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if contours:\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "            if cv2.contourArea(largest_contour) > 30:  # filter out noise\n",
        "                M = cv2.moments(largest_contour)\n",
        "                if M[\"m00\"] != 0:\n",
        "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                    cy = int(M[\"m01\"] / M[\"m00\"]) + y_top  # adjust to full-frame coordinates\n",
        "                    centroids[lane_idx] = (cx, cy)\n",
        "        # If no blob is detected and it's the first tracking frame, initialize on the left.\n",
        "        if lane_idx not in centroids and frame_index == 100:\n",
        "            init_x = int(0.1 * frame_width)\n",
        "            init_y = int((y_top + y_bottom) / 2)\n",
        "            centroids[lane_idx] = (init_x, init_y)\n",
        "\n",
        "    # Compute speed for each lane (in yards per second)\n",
        "    speeds = {}\n",
        "    for lane_idx in range(5):\n",
        "        if lane_idx in centroids and lane_idx in prev_centroids:\n",
        "            (prev_x, prev_y) = prev_centroids[lane_idx]\n",
        "            (curr_x, curr_y) = centroids[lane_idx]\n",
        "            distance = np.sqrt((curr_x - prev_x) ** 2 + (curr_y - prev_y) ** 2)\n",
        "            speeds[lane_idx] = (distance * fps) / pixels_per_yard\n",
        "        else:\n",
        "            speeds[lane_idx] = 0.0\n",
        "\n",
        "    # Dim the original frame\n",
        "    frame_dimmed = cv2.convertScaleAbs(frame_original, alpha=dim_factor, beta=0)\n",
        "\n",
        "    # Overlay centroids, labels, and speeds (all in bold green)\n",
        "    for lane_idx in range(5):\n",
        "        if lane_idx in centroids:\n",
        "            cx, cy = centroids[lane_idx]\n",
        "            cv2.circle(frame_dimmed, (cx, cy), 5, (0, 255, 0), -1)\n",
        "            cv2.putText(frame_dimmed, f\"Swimmer {lane_idx+1}\", (cx + 10, cy),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "            speed_text = f\"{speeds[lane_idx]:.1f} yd/s\"\n",
        "            cv2.putText(frame_dimmed, speed_text, (cx + 10, cy - 30),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "    # Update previous centroids for the next frame\n",
        "    prev_centroids = centroids.copy()\n",
        "\n",
        "    out_final.write(frame_dimmed)\n",
        "    frame_index += 1\n",
        "\n",
        "cap_tracked.release()\n",
        "cap_original.release()\n",
        "out_final.release()\n",
        "print(\"Final overlay complete. Output saved as 'final_tracked_200free.mp4'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVMAIGf_-Bah",
        "outputId": "522f9b28-1719-412b-abe0-f68bd5276289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using lane bounds: [(377, 426), (426, 482), (482, 551), (551, 619), (619, 706)]\n",
            "Final overlay complete. Output saved as 'final_tracked_200free.mp4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "print(\"Using lane bounds:\", lane_bounds)\n",
        "\n",
        "# Open the tracked swimmers video (which contains the tracking data) and the original video\n",
        "cap_tracked = cv2.VideoCapture(\"tracked_swimmers.mp4\")\n",
        "cap_original = cv2.VideoCapture(\"200free_rotated.mp4\")\n",
        "\n",
        "if not cap_tracked.isOpened() or not cap_original.isOpened():\n",
        "    print(\"Error: Could not open one or both videos.\")\n",
        "    exit()\n",
        "\n",
        "fps = int(cap_original.get(cv2.CAP_PROP_FPS))\n",
        "frame_width = int(cap_original.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap_original.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out_final = cv2.VideoWriter(\"final_tracked_200free.mp4\", fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "frame_index = 0\n",
        "# Dictionaries to store centroids for each lane (keys: 0 to 4)\n",
        "centroids = {}\n",
        "prev_centroids = {}\n",
        "\n",
        "# Conversion factor: 61.8 pixels per yard\n",
        "pixels_per_yard = 61.8\n",
        "\n",
        "# Dim factor (to make the original video a bit darker for overlay clarity)\n",
        "dim_factor = 0.7\n",
        "\n",
        "# Threshold frame: after 7 seconds, remove lane 5 (index 4) and shift labels by +1.\n",
        "threshold_frame = int(7 * fps)\n",
        "\n",
        "while True:\n",
        "    ret_tracked, frame_tracked = cap_tracked.read()\n",
        "    ret_original, frame_original = cap_original.read()\n",
        "\n",
        "    if not ret_tracked or not ret_original:\n",
        "        break\n",
        "\n",
        "    # For the first 100 frames, output the dimmed original frame unmodified.\n",
        "    if frame_index < 100:\n",
        "        frame_dimmed = cv2.convertScaleAbs(frame_original, alpha=dim_factor, beta=0)\n",
        "        out_final.write(frame_dimmed)\n",
        "        frame_index += 1\n",
        "        continue\n",
        "\n",
        "    # Process the tracked video frame to re-extract swimmer centroids.\n",
        "    gray_tracked = cv2.cvtColor(frame_tracked, cv2.COLOR_BGR2GRAY)\n",
        "    _, swimmer_mask = cv2.threshold(gray_tracked, 200, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Process each of the 5 lanes (using lane_bounds)\n",
        "    for lane_idx, (y_top, y_bottom) in enumerate(lane_bounds):\n",
        "        if lane_idx >= 5:\n",
        "            break  # only process 5 lanes\n",
        "\n",
        "        # Extract ROI corresponding to the lane (between the two red lines)\n",
        "        lane_roi = swimmer_mask[y_top:y_bottom, :]\n",
        "        contours, _ = cv2.findContours(lane_roi, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        if contours:\n",
        "            # Select the largest contour (assumed to be the swimmer)\n",
        "            largest_contour = max(contours, key=cv2.contourArea)\n",
        "            if cv2.contourArea(largest_contour) > 30:  # Filter out noise\n",
        "                M = cv2.moments(largest_contour)\n",
        "                if M[\"m00\"] != 0:\n",
        "                    cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "                    cy = int(M[\"m01\"] / M[\"m00\"]) + y_top  # adjust to full-frame coordinates\n",
        "                    centroids[lane_idx] = (cx, cy)\n",
        "        # If no blob is detected and it's the first tracking frame, initialize centroid on the left.\n",
        "        if lane_idx not in centroids and frame_index == 100:\n",
        "            init_x = int(0.1 * frame_width)\n",
        "            init_y = int((y_top + y_bottom) / 2)\n",
        "            centroids[lane_idx] = (init_x, init_y)\n",
        "\n",
        "    # Compute speed for each lane (in yards per second)\n",
        "    speeds = {}\n",
        "    for lane_idx in range(5):\n",
        "        if lane_idx in centroids and lane_idx in prev_centroids:\n",
        "            (prev_x, prev_y) = prev_centroids[lane_idx]\n",
        "            (curr_x, curr_y) = centroids[lane_idx]\n",
        "            distance = np.sqrt((curr_x - prev_x) ** 2 + (curr_y - prev_y) ** 2)\n",
        "            speeds[lane_idx] = (distance * fps) / pixels_per_yard\n",
        "        else:\n",
        "            speeds[lane_idx] = 0.0\n",
        "\n",
        "    # Dim the original frame\n",
        "    frame_dimmed = cv2.convertScaleAbs(frame_original, alpha=dim_factor, beta=0)\n",
        "\n",
        "    # Overlay centroids, labels, and speeds on the dimmed original frame.\n",
        "    if frame_index < threshold_frame:\n",
        "        # Before 7 seconds, draw all 5 lanes normally.\n",
        "        for lane_idx in range(5):\n",
        "            if lane_idx in centroids:\n",
        "                cx, cy = centroids[lane_idx]\n",
        "                cv2.circle(frame_dimmed, (cx, cy), 5, (0, 255, 0), -1)\n",
        "                cv2.putText(frame_dimmed, f\"Swimmer {lane_idx+1}\", (cx + 10, cy),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "                speed_text = f\"{speeds[lane_idx]:.1f} yd/s\"\n",
        "                cv2.putText(frame_dimmed, speed_text, (cx + 10, cy - 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "    else:\n",
        "        # After 7 seconds, do not consider lane 4 (swimmer 5) and shift labels by +1.\n",
        "        for lane_idx in range(4):  # Only lanes 0 to 3.\n",
        "            if lane_idx in centroids:\n",
        "                cx, cy = centroids[lane_idx]\n",
        "                cv2.circle(frame_dimmed, (cx, cy), 5, (0, 255, 0), -1)\n",
        "                # Shift label: lane 0 becomes \"Swimmer 2\", lane 1 becomes \"Swimmer 3\", etc.\n",
        "                label = f\"Swimmer {lane_idx+1+1}\"\n",
        "                cv2.putText(frame_dimmed, label, (cx + 10, cy),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "                speed_text = f\"{speeds[lane_idx]:.1f} yd/s\"\n",
        "                cv2.putText(frame_dimmed, speed_text, (cx + 10, cy - 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "        # Lane 4 (swimmer 5) is not drawn at all.\n",
        "\n",
        "    # Update previous centroids for the next frame.\n",
        "    prev_centroids = centroids.copy()\n",
        "\n",
        "    out_final.write(frame_dimmed)\n",
        "    frame_index += 1\n",
        "\n",
        "cap_tracked.release()\n",
        "cap_original.release()\n",
        "out_final.release()\n",
        "print(\"Final overlay complete. Output saved as 'final_video.mp4'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqiuAgw_p9vN",
        "outputId": "3e7be59e-198a-41a4-e74d-a92d9a6af54c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using lane bounds: [(377, 426), (426, 482), (482, 551), (551, 619), (619, 706)]\n",
            "Final overlay complete. Output saved as 'final_tracked_200free.mp4'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}